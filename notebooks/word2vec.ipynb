{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4403f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2af9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords =[\"Aspiring human resources\", \"seeking human resources\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00dca25-a6dc-43b1-a0f2-822bbeea363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = '../data/raw/potential-talents.csv'\n",
    "google_model_path = '../models/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd3d3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "id                                                      \n",
       "1   2019 C.T. Bauer College of Business Graduate (...   \n",
       "2   Native English Teacher at EPIK (English Progra...   \n",
       "3               Aspiring Human Resources Professional   \n",
       "4              People Development Coordinator at Ryan   \n",
       "5     Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                               location connection  fit  \n",
       "id                                                       \n",
       "1                        Houston, Texas         85  NaN  \n",
       "2                                Kanada      500+   NaN  \n",
       "3   Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "4                         Denton, Texas      500+   NaN  \n",
       "5                        İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(data_file_path, index_col = 'id')\n",
    "\n",
    "# Inspect data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "631b3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = df['job_title']\n",
    "sentences = list(set(title_df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea4b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# assuming the model is downloaded and stored in the path 'path/to/GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(google_model_path, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a83aeec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word2vec(sentence, model):\n",
    "    words = sentence.split()\n",
    "    word_vectors = [model[word] for word in words if word in model.index_to_key]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # return zero vector if no words in the sentence is in the vocabulary of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda4406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_vectors = [average_word2vec(sentence, model) for sentence in keywords]\n",
    "sentence_vectors = [average_word2vec(sentence, model) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "183e40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarities = cosine_similarity(keyword_vectors, sentence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb17f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar sentences to 'Aspiring human resources':\n",
      "   'Aspiring Human Resources Professional' with a similarity of 0.6287.\n",
      "   'Aspiring Human Resources Manager, seeking internship in Human Resources.' with a similarity of 0.6136.\n",
      "   'Aspiring Human Resources Specialist' with a similarity of 0.5983.\n",
      "   'Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment' with a similarity of 0.5976.\n",
      "   'Aspiring Human Resources Professional | An energetic and Team-Focused Leader' with a similarity of 0.5776.\n",
      "   'Aspiring Human Resources Management student seeking an internship' with a similarity of 0.5763.\n",
      "   'Student at Humber College and Aspiring Human Resources Generalist' with a similarity of 0.5338.\n",
      "   'Liberal Arts Major. Aspiring Human Resources Analyst.' with a similarity of 0.5240.\n",
      "   'Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis' with a similarity of 0.5219.\n",
      "   'Experienced Retail Manager and aspiring Human Resources Professional' with a similarity of 0.4839.\n",
      "---------\n",
      "Most similar sentences to 'seeking human resources':\n",
      "   'Aspiring Human Resources Manager, seeking internship in Human Resources.' with a similarity of 0.4707.\n",
      "   'Seeking Human Resources Opportunities' with a similarity of 0.4630.\n",
      "   'Human Resources professional for the world leader in GIS software' with a similarity of 0.4509.\n",
      "   'Seeking Human Resources HRIS and Generalist Positions' with a similarity of 0.4488.\n",
      "   'Aspiring Human Resources Management student seeking an internship' with a similarity of 0.4439.\n",
      "   'Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!!  (408) 709-2621' with a similarity of 0.4379.\n",
      "   'Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment' with a similarity of 0.4378.\n",
      "   'Seeking Human Resources Position' with a similarity of 0.4233.\n",
      "   'Seeking Human  Resources Opportunities. Open to travel and relocation.' with a similarity of 0.4056.\n",
      "   'Seeking employment opportunities within Customer Service or Patient Care' with a similarity of 0.3914.\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "top_10_similar_sentences = []\n",
    "\n",
    "for i, sentence in enumerate(keywords):\n",
    "    # Getting the indices of top 10 similar sentences\n",
    "    top_10_indices = similarities[i].argsort()[-10:][::-1] \n",
    "    \n",
    "    top_10_for_sentence = [(sentences[j], similarities[i][j]) for j in top_10_indices]\n",
    "    top_10_similar_sentences.append((sentence, top_10_for_sentence))\n",
    "\n",
    "# Printing the results\n",
    "for s1, top_10 in top_10_similar_sentences:\n",
    "    print(f\"Most similar sentences to '{s1}':\")\n",
    "    for s2, sim in top_10:\n",
    "        print(f\"   '{s2}' with a similarity of {sim:.4f}.\")\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9adfe80c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m         plt\u001B[38;5;241m.\u001B[39mtext(x\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m0.01\u001B[39m, y, label, fontsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m9\u001B[39m)\n\u001B[1;32m     13\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m---> 15\u001B[0m \u001B[43mplot_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence_vectors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msentences\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[22], line 6\u001B[0m, in \u001B[0;36mplot_embeddings\u001B[0;34m(embeddings, labels)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot_embeddings\u001B[39m(embeddings, labels):\n\u001B[1;32m      5\u001B[0m     tsne \u001B[38;5;241m=\u001B[39m TSNE(n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m     reduced_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mtsne\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m10\u001B[39m))\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(labels):\n",
      "File \u001B[0;32m~/PycharmProjects/apziva/kwjKuoMmbwSWxYXj/venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 140\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    142\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    143\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    144\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    145\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    146\u001B[0m         )\n",
      "File \u001B[0;32m~/PycharmProjects/apziva/kwjKuoMmbwSWxYXj/venv/lib/python3.10/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/apziva/kwjKuoMmbwSWxYXj/venv/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1110\u001B[0m, in \u001B[0;36mTSNE.fit_transform\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m   1085\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(\n\u001B[1;32m   1086\u001B[0m     \u001B[38;5;66;03m# TSNE.metric is not validated yet\u001B[39;00m\n\u001B[1;32m   1087\u001B[0m     prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1088\u001B[0m )\n\u001B[1;32m   1089\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1090\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001B[39;00m\n\u001B[1;32m   1091\u001B[0m \n\u001B[1;32m   1092\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001B[39;00m\n\u001B[1;32m   1109\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_params_vs_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m     embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit(X)\n\u001B[1;32m   1112\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_ \u001B[38;5;241m=\u001B[39m embedding\n",
      "File \u001B[0;32m~/PycharmProjects/apziva/kwjKuoMmbwSWxYXj/venv/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:820\u001B[0m, in \u001B[0;36mTSNE._check_params_vs_input\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    819\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_params_vs_input\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m--> 820\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperplexity \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mperplexity must be less than n_samples\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_embeddings(embeddings, labels):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = reduced_embeddings[i]\n",
    "        plt.scatter(x, y, marker='x', color='red')\n",
    "        plt.text(x+0.01, y, label, fontsize=9)\n",
    "    plt.show()\n",
    "\n",
    "plot_embeddings(sentence_vectors, sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144eeb4-94c9-41bc-a222-e2f099eda34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
